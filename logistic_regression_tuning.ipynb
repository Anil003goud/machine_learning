{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2783d4da",
   "metadata": {},
   "source": [
    "## Regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e8daf",
   "metadata": {},
   "source": [
    "**model has three models**\n",
    "\n",
    " - under fit : high bias - Low variance\n",
    "        \n",
    " - Normal fit : low bias - low variance\n",
    "    \n",
    " - over fit : low bias - high variance\n",
    "    \n",
    "    \n",
    "why model becomes over fit\n",
    "\n",
    "- data is not enough\n",
    "\n",
    "- model complexity\n",
    "\n",
    "     - Linear regression what is meaning of model complexity\n",
    "    \n",
    "              - increase the features or columns\n",
    "     \n",
    "    -  Logistic regression what is meaning of model complex\n",
    "    \n",
    "              - increase the features or columns\n",
    "        \n",
    "    - KNN\n",
    "    \n",
    "            - k=1(choose the neighbours)\n",
    "        \n",
    "    - DT\n",
    "    \n",
    "            - Depth of the trees is the model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ede85d",
   "metadata": {},
   "source": [
    "L1 Regularization :\n",
    "    \n",
    "    power : 1\n",
    "        \n",
    "    Lasso\n",
    "    \n",
    "L2 Regularization :\n",
    "    \n",
    "    power : 2\n",
    "        \n",
    "    Ridge\n",
    "    \n",
    "aviods over fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7cd73",
   "metadata": {},
   "source": [
    "For any over fitting model cost function j becomes zero\n",
    "\n",
    "regularization methos cost function equal to j + (slope)**2\n",
    "\n",
    "when we use regularization methods eventhough j becomes zero,\n",
    "\n",
    "still we can see some error in the form of slope\n",
    "\n",
    "this indicates still we need to do some developments in order to reduce the cost function\n",
    "\n",
    "in this process it will automatically aviods the over fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64c763",
   "metadata": {},
   "source": [
    "**overfit : Extact actual data is predicted by model**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe078ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 0.49867516307458876\n",
      "R2 squared 0.2369231952235108\n",
      "RMSE 0.706169358634732\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(r'C:\\Users\\anilg\\Ds naresh it\\vscode\\stream_lit\\Linear_regression_with_streamlit\\winequality_red.csv')\n",
    "x=df.drop('quality',axis=1)\n",
    "y=df['quality']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "# split the data\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# fit lasso regression (L1 regression)\n",
    "lasso_reg=Lasso(alpha=0.1)\n",
    "lasso_reg.fit(x_train,y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred=lasso_reg.predict(x_test)\n",
    "\n",
    "\n",
    "# calculate mean squared error\n",
    "Mse=mean_squared_error(y_test,y_pred)\n",
    "print(\"mean squared error\",Mse)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "RMSE = np.sqrt(Mse)\n",
    "print(\"R2 squared\",R2)\n",
    "print(\"RMSE\",RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6688bb9",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf114b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 0.39079450472195915\n",
      "R2 squared 0.4020030591681194\n",
      "RMSE 0.6251355890700506\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(r'C:\\Users\\anilg\\Ds naresh it\\vscode\\stream_lit\\Linear_regression_with_streamlit\\winequality_red.csv')\n",
    "x=df.drop('quality',axis=1)\n",
    "y=df['quality']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "# split the data\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# fit ridge regression (L2 regression)\n",
    "ridge_reg=Ridge(alpha=0.1)\n",
    "ridge_reg.fit(x_train,y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred=ridge_reg.predict(x_test)\n",
    "\n",
    "\n",
    "# calculate mean squared error\n",
    "Mse=mean_squared_error(y_test,y_pred)\n",
    "print(\"mean squared error\",Mse)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "RMSE = np.sqrt(Mse)\n",
    "print(\"R2 squared\",R2)\n",
    "print(\"RMSE\",RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b35ce",
   "metadata": {},
   "source": [
    "## Elastic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b779e6",
   "metadata": {},
   "source": [
    "$Elastic$ $Net$ $Regression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac5593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 0.4880295981151681\n",
      "R2 squared 0.25321312561465037\n",
      "RMSE 0.6251355890700506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\anilg\\Ds naresh it\\vscode\\stream_lit\\Linear_regression_with_streamlit\\winequality_red.csv')\n",
    "x=df.drop('quality',axis=1)\n",
    "y=df['quality']\n",
    "\n",
    "# split the data\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# fit the Elastic Net model\n",
    "elastic_net=ElasticNet(alpha=0.1,l1_ratio=0.5)\n",
    "elastic_net.fit(x_train,y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred=elastic_net.predict(x_test)\n",
    "\n",
    "\n",
    "# calculate mean square error\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(\"mean squared error\",mse)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "RMSE = np.sqrt(Mse)\n",
    "print(\"R2 squared\",R2)\n",
    "print(\"RMSE\",RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdcaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
